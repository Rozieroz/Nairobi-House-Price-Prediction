{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef7680d",
   "metadata": {},
   "source": [
    "# # Day 3: Baseline Model for Nairobi House Price Prediction\n",
    "# \n",
    "**Goal:** Build a simple linear regression model, evaluate its performance, and extract insights about price drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3902f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from collections import Counter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5014d70",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load clean data (from Day 2)\n",
    "df = pd.read_csv('../data/clean_listings.csv')\n",
    "print(f\"Clean data shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b284cef",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#   2. Exploratory Analysis – Answer Key Questions\n",
    "\n",
    "# ===================================================================================\n",
    "#  1. Most Expensive Locations\n",
    "\n",
    "\n",
    "# Median price by location (in millions KSh)\n",
    "location_median = df.groupby('Location')['Price_Millions'].median().sort_values(ascending=False)\n",
    "print(\"Top 10 most expensive locations (median price in M KSh):\")\n",
    "print(location_median.head(10))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "location_median.head(15).plot(kind='bar')\n",
    "plt.title('Top 15 Locations by Median Price')\n",
    "plt.ylabel('Median Price (Millions KSh)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/location_median_price.png')\n",
    "plt.show()\n",
    "\n",
    "# ===================================================================================\n",
    "#  2 How Strongly Does Size Affect Price?\n",
    "\n",
    "\n",
    "corr = df['Size_SQM'].corr(df['Price_Millions'])\n",
    "print(f\"Correlation between Size (sqm) and Price: {corr:.2f}\")\n",
    "\n",
    "# Scatter plot with regression line\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.regplot(x='Size_SQM', y='Price_Millions', data=df, scatter_kws={'alpha':0.5})\n",
    "plt.title(f'Price vs Size (corr = {corr:.2f})')\n",
    "plt.xlabel('Size (sqm)')\n",
    "plt.ylabel('Price (Millions KSh)')\n",
    "plt.savefig('../reports/price_vs_size.png')\n",
    "plt.show()\n",
    "\n",
    "# ===================================================================================\n",
    "#  3 Which Amenities Increase Value Most?\n",
    "# \n",
    "# To isolate the effect of amenities, run a regression that controls for size and location.\n",
    "\n",
    "\n",
    "# Flatten all amenities to get the most common ones\n",
    "all_amenities = []\n",
    "for x in df['Amenities']:\n",
    "    if isinstance(x, list):\n",
    "        all_amenities.extend(x)\n",
    "    elif isinstance(x, str):\n",
    "        all_amenities.extend([a.strip() for a in x.split(',')])\n",
    "\n",
    "top_10_amenities = [item for item, count in Counter(all_amenities).most_common(10)]\n",
    "print(\"Top 10 amenities:\", top_10_amenities)\n",
    "\n",
    "# Create dummy variables for top amenities---- convert text amenities into binary columns\n",
    "amenity_dummies = df['Amenities'].str.get_dummies(sep=', ')[top_10_amenities]\n",
    "\n",
    "# Location dummies (drop first to avoid multicollinearity - 2 or more features having same info)\n",
    "location_dummies = pd.get_dummies(df['Location'], drop_first=True)\n",
    "\n",
    "# Combine features\n",
    "X_amen = pd.concat([df[['Size_SQM']], location_dummies, amenity_dummies], axis=1).astype(float)\n",
    "y_amen = df['Price_Millions'].astype(float)\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "mask = X_amen.notnull().all(axis=1) & y_amen.notnull()\n",
    "X_amen = X_amen[mask]\n",
    "y_amen = y_amen[mask]\n",
    "\n",
    "# Add constant for OLS\n",
    "X_amen = sm.add_constant(X_amen)\n",
    "\n",
    "# Fit model\n",
    "model_amen = sm.OLS(y_amen, X_amen).fit()\n",
    "print(model_amen.summary())\n",
    "\n",
    "# Extract coefficients for the top amenities\n",
    "amenity_effects = model_amen.params[top_10_amenities]\n",
    "amenity_pvals = model_amen.pvalues[top_10_amenities]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Coefficient (M KSh)': amenity_effects,\n",
    "    'P-value': amenity_pvals\n",
    "}).sort_values('Coefficient (M KSh)', ascending=False)\n",
    "\n",
    "print(\"\\nAmenity Value Impact (Controlled for Size & Location):\")\n",
    "print(results_df)\n",
    "\n",
    "# Plot with confidence intervals\n",
    "std_err = model_amen.bse[top_10_amenities]\n",
    "ci_lower = amenity_effects - 1.96 * std_err\n",
    "ci_upper = amenity_effects + 1.96 * std_err\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(results_df.index, results_df['Coefficient (M KSh)'],\n",
    "         xerr=[results_df['Coefficient (M KSh)'] - ci_lower, ci_upper - results_df['Coefficient (M KSh)']],\n",
    "         color='skyblue', edgecolor='black')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Estimated Price Impact (M KSh)')\n",
    "plt.title('Top 10 Amenities: Price Impact (Controlled for Size & Location)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/amenity_impact.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11672fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#   3. Prepare Features for Baseline Model\n",
    "# \n",
    "# use:\n",
    "# - `Size_SQM`\n",
    "# - `Bedrooms_Num`\n",
    "# - `Bathrooms_Num`\n",
    "# - `Amenity_Count` (count of amenities)\n",
    "# - Dummy variables for the top 10 locations\n",
    "\n",
    "\n",
    "# Handle missing values in Bedrooms_Num and Bathrooms_Num\n",
    "print(\"Missing values before imputation:\")\n",
    "print(df[['Bedrooms_Num', 'Bathrooms_Num']].isnull().sum())\n",
    "\n",
    "# Impute Bathrooms_Num with median (13 missing)\n",
    "median_bathrooms = df['Bathrooms_Num'].median()\n",
    "df['Bathrooms_Num'] = df['Bathrooms_Num'].fillna(median_bathrooms)\n",
    "\n",
    "# Bedrooms_Num has no missing values\n",
    "\n",
    "# Create dummies for top 10 locations\n",
    "top_locs = df['Location'].value_counts().head(10).index\n",
    "for loc in top_locs:\n",
    "    df[f'Loc_{loc}'] = (df['Location'] == loc).astype(int)\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = ['Size_SQM', 'Bedrooms_Num', 'Bathrooms_Num', 'Amenity_Count'] + [f'Loc_{loc}' for loc in top_locs]\n",
    "X = df[feature_cols].fillna(0)  # final safety net\n",
    "y = df['Price_Millions']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8faae",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#   4. Train/Test Split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6cdab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#   5. Train Linear Regression\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3d20b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#   6. Evaluate the Model\n",
    "\n",
    "\n",
    "# Train metrics\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# Test metrics\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Train MAE: {:.2f}M KSh\".format(mae_train))\n",
    "print(\"Train RMSE: {:.2f}M KSh\".format(rmse_train))\n",
    "print(\"Train R²: {:.3f}\".format(r2_train))\n",
    "print(\"\\nTest MAE: {:.2f}M KSh\".format(mae_test))\n",
    "print(\"Test RMSE: {:.2f}M KSh\".format(rmse_test))\n",
    "print(\"Test R²: {:.3f}\".format(r2_test))\n",
    "\n",
    "# ===================================================================================\n",
    "# **Interpretation:**  \n",
    "# - MAE (Mean Absolute Error) tells  the average prediction error in millions of KSh. Our test MAE of about 8.4M means we're off by that much on average.  \n",
    "# - R² of 0.68 means our model explains 68% of the price variance – a decent baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2205abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#   7. Feature Importance (Coefficients)\n",
    "\n",
    "\n",
    "# Create a DataFrame of coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': lr.coef_\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "# Add the intercept separately\n",
    "intercept_df = pd.DataFrame({'feature': ['Intercept'], 'coefficient': [lr.intercept_]})\n",
    "coef_df = pd.concat([intercept_df, coef_df], ignore_index=True)\n",
    "\n",
    "print(coef_df)\n",
    "\n",
    "# Plot coefficients (excluding intercept for scale)\n",
    "plt.figure(figsize=(10,8))\n",
    "plot_df = coef_df[coef_df['feature'] != 'Intercept'].sort_values('coefficient', ascending=True)\n",
    "plt.barh(plot_df['feature'], plot_df['coefficient'])\n",
    "plt.xlabel('Coefficient (impact on price in M KSh)')\n",
    "plt.title('Linear Regression Coefficients')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/coefficients.png')\n",
    "plt.show()\n",
    "\n",
    "# ===================================================================================\n",
    "# **Observations:**  \n",
    "# - Location dummies (e.g., `Loc_Kitusuru`) have large positive coefficients – location is the strongest driver.  \n",
    "# - `Size_SQM` adds about 0.15M per sqm (150,000 KSh).  \n",
    "# - `Amenity_Count` adds roughly 0.8M per additional amenity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012432f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#   8. Save Model \n",
    "# \n",
    "# save the model for later use (maybe in Streamlit- Day 5).\n",
    "\n",
    "\n",
    "# Save the model using joblib as .pkl file - common format for scikit-learn models\n",
    "import joblib\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)  # ensure models directory exists\n",
    "joblib.dump(lr, '../models/linear_baseline.pkl')\n",
    "print(\"Model saved to ../models/linear_baseline.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312env (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
